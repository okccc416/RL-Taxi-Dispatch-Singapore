# Reinforcement Learning for On-Demand Taxi Dynamics

> **Master's Dissertation** â€” Nanyang Technological University  
> Multi-Agent Reinforcement Learning for Real-Time Fleet Rebalancing over Singapore's Road Network

---

## Architecture â€” Centralized Training, Decentralized Execution (CTDE)

```
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚          Shared PPO Policy Network       â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚
                     â”‚  â”‚ FC (256) â”‚â†’ â”‚ FC (256) â”‚â†’ â”‚Softmaxâ”‚ â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                     â”‚         â†‘ Action Mask (âˆ’âˆ on invalid)   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚  Parameter Sharing
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                     â–¼                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Taxi  0 â”‚          â”‚ Taxi  1 â”‚   ...    â”‚ Taxi N-1â”‚
     â”‚ obs â†’ a â”‚          â”‚ obs â†’ a â”‚          â”‚ obs â†’ a â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
          â”‚                    â”‚                    â”‚
          â–¼                    â–¼                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         H3-Discretised Singapore Road Network         â”‚
    â”‚         (Uber H3 Resolution 8 Hexagonal Grid)         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Every taxi is an independent agent but shares the **same policy network** (parameter sharing).
During training, all agents contribute gradients to one set of weights.
During execution, each taxi runs the policy locally using only its own observation â€” no central coordinator needed.

### Core Innovation â€” Density Penalty

The reward function includes a **density penalty** that creates anti-bunching pressure:

```
R = E[Revenue] âˆ’ Travel Cost âˆ’ Î± Â· max(0, supply/demand âˆ’ 1)
```

When Î± = 0.5 (PPO-Ours), the policy learns to spatially disperse.
When Î± = 0.0 (PPO-Ablation), taxis cluster at hotspots â€” proving the penalty's necessity.

---

## Project Structure

```
â”œâ”€â”€ data_pipeline.py          # Road network, H3 discretisation, tidal Poisson demand
â”œâ”€â”€ cityflow_env.py           # Gymnasium env with CityFlow + action masking
â”œâ”€â”€ train_rllib.py            # Ray RLlib PPO training (CTDE, --ablation flag)
â”œâ”€â”€ evaluate_and_plot.py      # Multi-seed evaluation, ablation study, publication plots
â”œâ”€â”€ kafka_producer.py         # Simulated real-time passenger request stream
â”œâ”€â”€ decision_gateway.py       # RL inference gateway + WebSocket broadcast
â”œâ”€â”€ dashboard/                # Next.js real-time dispatch visualisation
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Makefile                  # One-command pipeline orchestration
â”œâ”€â”€ figures/                  # Generated publication-quality plots (300 DPI)
â”œâ”€â”€ results/                  # Evaluation CSVs (multi-seed, spatial snapshots)
â”œâ”€â”€ checkpoints_ours/         # Trained PPO model (Î± = 0.5)
â””â”€â”€ checkpoints_ablation/     # Ablation baseline (Î± = 0.0)
```

---

## Quick Start

### Prerequisites

- Python 3.10+
- Node.js 18+ (for dashboard)
- CUDA GPU (optional, for faster training)

### Installation

```bash
pip install -r requirements.txt
```

### Run the Full Pipeline

```bash
# One command â€” data â†’ train both models â†’ evaluate
make all

# Or step by step:
make data                      # Generate road network + tidal demand
make train-ours                # Train PPO with density penalty
make train-ablation            # Train PPO without density penalty (ablation)
make evaluate                  # Multi-seed evaluation + plots
```

### Launch the Dashboard

```bash
# Terminal 1: Start the RL dispatch WebSocket server
python decision_gateway.py --standalone

# Terminal 2: Start the dashboard
make dashboard
# â†’ Open http://localhost:3000
```

---

## Observation Space (per agent)

| Slice | Feature |
|---|---|
| `[0 â€¦ H)` | One-hot H3 hex ID |
| `[H]` | Demand âˆ’ Supply gap at current hex |
| `[H+1 â€¦ H+7)` | Demand âˆ’ Supply gap at 6 neighbours |
| `[H+7]` | Idle vehicle count at current hex |
| `[H+8 â€¦ H+14)` | Idle vehicle count at 6 neighbours |
| `[H+14]` | Normalised time-of-day |

**Action Space**: `Discrete(7)` â€” 0 = stay, 1â€“6 = move to sorted H3 neighbour.

---

## Ablation Study Results

Evaluation over 3 random seeds (42, 1024, 2026) with 20 taxis on Downtown Core, Singapore:

| Algorithm | Mean ORR | Cumulative Reward | Matched Orders | Cruising Hops |
|---|---|---|---|---|
| **PPO-Ours (Î±=0.5)** | **0.405 Â± 0.231** | **+4,465** | **4,535** | **1,230** |
| PPO-Ablation (Î±=0.0) | 0.172 Â± 0.181 | +1,259 | 1,576 | 2,164 |
| Greedy | 0.214 Â± 0.099 | +3,323 | 3,372 | 2,749 |
| Random | 0.337 Â± 0.194 | +3,578 | 3,948 | 4,579 |

**Key finding**: Removing the density penalty (Î± = 0 â†’ 0.5) causes the learned policy to cluster aggressively, performing worse than even a random baseline. The anti-bunching reward is essential.

---

## Tidal Demand Profile

Demand follows a bi-modal Gaussian tidal curve with peaks at 08:00 (AM rush) and 18:00 (PM rush), calibrated for Singapore's Downtown Core:

```
Î»(t, h) = Î»_base(h) Ã— [ 0.15 + 2.8Â·ğ’©(96, 22Â²) + 2.3Â·ğ’©(216, 22Â²) + 0.7Â·ğ’©(156, 36Â²) ]
```


---

## Tech Stack

| Layer | Technology |
|---|---|
| Spatial & Graph | `osmnx`, `h3-py`, `networkx`, `geopandas` |
| Simulation | `CityFlow` (macro traffic), Gymnasium |
| Reinforcement Learning | `Ray RLlib` (PPO), `torch` |
| Streaming | `kafka-python-ng`, `websockets` |
| Visualisation | `matplotlib`, `seaborn`, `deck.gl`, `Next.js` |

---

